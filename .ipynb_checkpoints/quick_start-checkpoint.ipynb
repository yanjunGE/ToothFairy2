{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Number of GPU devices: 1\n",
      "Current GPU device index: 0\n",
      "Current GPU device name: NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(\"CUDA Available:\", cuda_available)\n",
    "\n",
    "# If available, display GPU details\n",
    "if cuda_available:\n",
    "    print(\"Number of GPU devices:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU device index:\", torch.cuda.current_device())\n",
    "    print(\"Current GPU device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is running on CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\geyan\\.conda\\envs\\monai-dev\\Lib\\site-packages\\ignite\\handlers\\checkpoint.py:17: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
      "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
      "Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "Importing from timm.models.registry is deprecated, please import via timm.models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown arguments: ['-f', 'C:\\\\Users\\\\geyan\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-25972330-fa3e-4687-8f75-0da5e7dfa35e.json']\n",
      "Unknown arguments: ['-f', 'C:\\\\Users\\\\geyan\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-25972330-fa3e-4687-8f75-0da5e7dfa35e.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from skimage import io\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from tensorboardX import SummaryWriter\n",
    "#from dataset import *\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cfg\n",
    "import function\n",
    "from conf import settings\n",
    "#from models.discriminatorlayer import discriminator\n",
    "from dataset import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# 定义源文件夹和目标文件夹\n",
    "source_folder1 = \"./data_test/Dataset/images\"\n",
    "source_folder2 = \"./data_test/Dataset/labels\"\n",
    "target_folder1 = \"./data/Dataset/images\"\n",
    "target_folder2 = \"./data/Dataset/labels\"\n",
    "\n",
    "# 定义处理函数\n",
    "def process_files(source_folder, target_folder):\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        if not file_name.endswith(\".mha\"):  # 忽略非MHA文件\n",
    "            continue\n",
    "        \n",
    "        # 获取完整路径\n",
    "        input_path = os.path.join(source_folder, file_name)\n",
    "        image = sitk.ReadImage(input_path)\n",
    "        array = sitk.GetArrayFromImage(image)\n",
    "\n",
    "        # 打印原图尺寸\n",
    "        print(f\"Processing file: {file_name}\")\n",
    "        print(f\"Original image dimensions (D, H, W): {array.shape}\")\n",
    "        \n",
    "        # 检查文件名模式并生成新文件名\n",
    "        file_base, file_ext = os.path.splitext(file_name)\n",
    "        if file_base.endswith(\"_0000\"):\n",
    "            name_base = file_base[:-5]  # 去掉 \"_0000\"\n",
    "            template = f\"{name_base}_x_0000{file_ext}\"\n",
    "        else:\n",
    "            name_base = file_base\n",
    "            template = f\"{name_base}_x{file_ext}\"\n",
    "        \n",
    "        # 获取深度并切分\n",
    "        depth, height, width = array.shape\n",
    "        slice_size = depth // 8\n",
    "        for idx in range(8):\n",
    "            start_idx = idx * slice_size\n",
    "            end_idx = (idx + 1) * slice_size if idx < 7 else depth\n",
    "            slice_array = array[start_idx:end_idx]\n",
    "\n",
    "            # 转换为SimpleITK图像\n",
    "            slice_image = sitk.GetImageFromArray(slice_array)\n",
    "\n",
    "            # 复制元数据（方向、原点、间距）\n",
    "            slice_image.SetDirection(image.GetDirection())\n",
    "            slice_image.SetOrigin(image.GetOrigin())\n",
    "            spacing = list(image.GetSpacing())\n",
    "            spacing[2] = spacing[2] * (slice_array.shape[0] / depth)  # 更新Z方向间距\n",
    "            slice_image.SetSpacing(spacing)\n",
    "\n",
    "            # 打印切片尺寸\n",
    "            print(f\"Slice {idx + 1} dimensions (D, H, W): {slice_array.shape}\")\n",
    "\n",
    "            # 动态生成目标文件名\n",
    "            output_name = template.replace(\"_x\", f\"_x{idx + 1}\")\n",
    "            output_path = os.path.join(target_folder, output_name)\n",
    "\n",
    "            # 保存到目标文件夹\n",
    "            sitk.WriteImage(slice_image, output_path)\n",
    "            print(f\"Saved slice {idx + 1} to {output_path}\")\n",
    "\n",
    "# 分别处理两个文件夹\n",
    "process_files(source_folder1, target_folder1)\n",
    "process_files(source_folder2, target_folder2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown arguments: ['-f', 'C:\\\\Users\\\\geyan\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-25972330-fa3e-4687-8f75-0da5e7dfa35e.json']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "Namespace(net='sam', baseline='unet', encoder='default', seg_net='transunet', mod='sam_adpt', exp_name='msa_test_isic', type='map', vis=10, reverse=False, pretrain=False, val_freq=5, gpu=True, gpu_device=0, sim_gpu=0, epoch_ini=1, image_size=256, out_size=256, patch_size=2, dim=512, depth=1, heads=16, mlp_dim=1024, w=4, b=1, s=True, warm=1, lr=0.0001, uinch=1, imp_lr=0.0003, weights=0, base_weights=0, sim_weights=0, distributed='none', dataset='toothfairy', sam_ckpt='sam_vit_b_01ec64.pth', thd=True, chunk=None, num_sample=4, roi_size=96, evl_chunk=None, mid_dim=None, multimask_output=49, data_path='C:/Users/geyan/Projet_IAV/Medical-SAM-Adapter-main/data', path_helper={'prefix': 'logs\\\\msa_test_isic_2025_01_23_18_05_25', 'ckpt_path': 'logs\\\\msa_test_isic_2025_01_23_18_05_25\\\\Model', 'log_path': 'logs\\\\msa_test_isic_2025_01_23_18_05_25\\\\Log', 'sample_path': 'logs\\\\msa_test_isic_2025_01_23_18_05_25\\\\Samples'})\n"
     ]
    }
   ],
   "source": [
    "args = cfg.parse_args()\n",
    "\n",
    "GPUdevice = torch.device('cuda', args.gpu_device)\n",
    "\n",
    "net = get_network(args, args.net, use_gpu=args.gpu, gpu_device=GPUdevice, distribution = args.distributed)\n",
    "if args.pretrain:\n",
    "    weights = torch.load(args.pretrain)\n",
    "    net.load_state_dict(weights,strict=False)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=args.lr, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5) #learning rate decay\n",
    "\n",
    "'''load pretrained model'''\n",
    "if args.weights != 0:\n",
    "    print(f'=> resuming from {args.weights}')\n",
    "    assert os.path.exists(args.weights)\n",
    "    checkpoint_file = os.path.join(args.weights)\n",
    "    assert os.path.exists(checkpoint_file)\n",
    "    loc = 'cuda:{}'.format(args.gpu_device)\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=loc)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_tol = checkpoint['best_tol']\n",
    "\n",
    "    net.load_state_dict(checkpoint['state_dict'],strict=False)\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer'], strict=False)\n",
    "\n",
    "    args.path_helper = checkpoint['path_helper']\n",
    "    logger = create_logger(args.path_helper['log_path'])\n",
    "    print(f'=> loaded checkpoint {checkpoint_file} (epoch {start_epoch})')\n",
    "\n",
    "args.path_helper = set_log_dir('logs', args.exp_name)\n",
    "logger = create_logger(args.path_helper['log_path'])\n",
    "logger.info(args)\n",
    "\n",
    "nice_train_loader, nice_test_loader = get_dataloader(args)\n",
    "# 打印加载后的数据张量大小\n",
    "#for batch_idx, data in enumerate(nice_train_loader):\n",
    "#    imgs, masks = data['image'], data['label']\n",
    "#    print(f\"批次 {batch_idx} 的图像张量大小: {imgs.shape}\")\n",
    "#    print(f\"批次 {batch_idx} 的标签张量大小: {masks.shape}\")\n",
    "#    break  # 仅打印第一个批次\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''checkpoint path and tensorboard'''\n",
    "# iter_per_epoch = len(Glaucoma_training_loader)\n",
    "checkpoint_path = os.path.join(settings.CHECKPOINT_PATH, args.net, settings.TIME_NOW)\n",
    "#use tensorboard\n",
    "if not os.path.exists(settings.LOG_DIR):\n",
    "    os.mkdir(settings.LOG_DIR)\n",
    "writer = SummaryWriter(log_dir=os.path.join(\n",
    "        settings.LOG_DIR, args.net, settings.TIME_NOW))\n",
    "# input_tensor = torch.Tensor(args.b, 3, 256, 256).cuda(device = GPUdevice)\n",
    "# writer.add_graph(net, Variable(input_tensor, requires_grad=True))\n",
    "\n",
    "#create checkpoint folder to save model\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    os.makedirs(checkpoint_path)\n",
    "checkpoint_path = os.path.join(checkpoint_path, '{net}-{epoch}-{type}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 110652157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 110652157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                | 0/177 [00:59<?, ?img/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m net\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     42\u001b[0m time_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 44\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_sam\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnice_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m || @ epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     46\u001b[0m time_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[1;32m~\\Projet_IAV\\Medical-SAM-Adapter-main\\function.py:154\u001b[0m, in \u001b[0;36mtrain_sam\u001b[1;34m(args, net, optimizer, train_loader, epoch, writer, schedulers, vis)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m n, value \u001b[38;5;129;01min\u001b[39;00m net\u001b[38;5;241m.\u001b[39mimage_encoder\u001b[38;5;241m.\u001b[39mnamed_parameters(): \n\u001b[0;32m    152\u001b[0m         value\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m imge\u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msam\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmobile_sam\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\monai-dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monai-dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Projet_IAV\\Medical-SAM-Adapter-main\\models\\sam\\modeling\\image_encoder.py:134\u001b[0m, in \u001b[0;36mImageEncoderViT.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    131\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m new_abs_pos\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m--> 134\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneck(x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\.conda\\envs\\monai-dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monai-dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Projet_IAV\\Medical-SAM-Adapter-main\\models\\ImageEncoder\\vit\\adapter_block.py:94\u001b[0m, in \u001b[0;36mAdapterBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     91\u001b[0m     xd \u001b[38;5;241m=\u001b[39m rearrange(xd, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(b n) dh dw c ->(b dh dw) n c\u001b[39m\u001b[38;5;124m'\u001b[39m, n\u001b[38;5;241m=\u001b[39m hh \u001b[38;5;241m*\u001b[39m ww )\n\u001b[0;32m     93\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x)\n\u001b[1;32m---> 94\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSpace_Adapter(x)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mthd:\n",
      "File \u001b[1;32m~\\.conda\\envs\\monai-dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\monai-dev\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\Projet_IAV\\Medical-SAM-Adapter-main\\models\\ImageEncoder\\vit\\adapter_block.py:158\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# q, k, v with shape (B * nHead, H * W, C)\u001b[39;00m\n\u001b[0;32m    156\u001b[0m q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m3\u001b[39m, B \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, H \u001b[38;5;241m*\u001b[39m W, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 158\u001b[0m attn \u001b[38;5;241m=\u001b[39m (\u001b[43mq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m) \u001b[38;5;241m@\u001b[39m k\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_rel_pos:\n\u001b[0;32m    161\u001b[0m     attn \u001b[38;5;241m=\u001b[39m add_decomposed_rel_pos(attn, q, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_h, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrel_w, (H, W), (H, W))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "'''begain training'''\n",
    "best_acc = 0.0\n",
    "best_tol = 1e4\n",
    "best_dice = 0.0\n",
    "\n",
    "# Print the total number of parameters\n",
    "num_params = sum(p.numel() for p in net.parameters())\n",
    "logger.info(f\"Total number of parameters: {num_params}\")\n",
    "print(f\"Total number of parameters: {num_params}\")\n",
    "\n",
    "def print_model_details(model):\n",
    "    print(\"Model Structure:\")\n",
    "    print(model)\n",
    "    print(\"\\nDetailed Layer-wise Parameters:\")\n",
    "    total_params = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_params = param.numel()\n",
    "        total_params += layer_params\n",
    "        print(f\"Layer: {name} | Parameters: {layer_params}\")\n",
    "    print(f\"\\nTotal Parameters: {total_params}\")\n",
    "\n",
    "# print_model_details(net)\n",
    "\n",
    "\n",
    "for epoch in range(settings.EPOCH):\n",
    "    # if epoch and epoch < 5:\n",
    "    #     if args.dataset != 'REFUGE':\n",
    "    #         tol, (eiou, edice) = function.validation_sam(args, nice_test_loader, epoch, net, writer)\n",
    "    #         logger.info(f'Total score: {tol}, IOU: {eiou}, DICE: {edice} || @ epoch {epoch}.')\n",
    "    #     else:\n",
    "    #         tol, (eiou_cup, eiou_disc, edice_cup, edice_disc) = function.validation_sam(args, nice_test_loader, epoch, net, writer)\n",
    "    #         logger.info(f'Total score: {tol}, IOU_CUP: {eiou_cup}, IOU_DISC: {eiou_disc}, DICE_CUP: {edice_cup}, DICE_DISC: {edice_disc} || @ epoch {epoch}.')\n",
    "    if epoch and epoch < 30:\n",
    "        if args.dataset != 'REFUGE':\n",
    "            # 接收返回的五个值\n",
    "            tol, avg_iou, avg_dice, iou_per_class, dice_per_class = function.validation_sam(args, nice_test_loader, epoch, net, writer)\n",
    "            logger.info(f'Total loss: {tol}, Average IOU: {avg_iou}, Average Dice: {avg_dice}')\n",
    "            # 如果需要展示每个类别的指标\n",
    "            for i, (iou, dice) in enumerate(zip(iou_per_class, dice_per_class)):\n",
    "                logger.info(f'Class {i}: IOU={iou:.4f}, Dice={dice:.4f}')\n",
    "    net.train()\n",
    "    time_start = time.time()\n",
    "    \n",
    "    loss = function.train_sam(args, net, optimizer, nice_train_loader, epoch, writer, vis = args.vis)\n",
    "    logger.info(f'Train loss: {loss} || @ epoch {epoch}.')\n",
    "    time_end = time.time()\n",
    "    print('time_for_training ', time_end - time_start)\n",
    "\n",
    "    net.eval()\n",
    "    if epoch and epoch % args.val_freq == 0 or epoch == settings.EPOCH-1:\n",
    "        # if args.dataset != 'REFUGE':\n",
    "        #     tol, (eiou, edice) = function.validation_sam(args, nice_test_loader, epoch, net, writer)\n",
    "        #     logger.info(f'Total score: {tol}, IOU: {eiou}, DICE: {edice} || @ epoch {epoch}.')\n",
    "        # else:\n",
    "        #     tol, (eiou_cup, eiou_disc, edice_cup, edice_disc) = function.validation_sam(args, nice_test_loader, epoch, net, writer)\n",
    "        #     logger.info(f'Total score: {tol}, IOU_CUP: {eiou_cup}, IOU_DISC: {eiou_disc}, DICE_CUP: {edice_cup}, DICE_DISC: {edice_disc} || @ epoch {epoch}.')\n",
    "        if args.dataset != 'REFUGE':\n",
    "            # 接收返回的五个值\n",
    "            tol, avg_iou, avg_dice, iou_per_class, dice_per_class = function.validation_sam(args, nice_test_loader, epoch, net, writer)\n",
    "            logger.info(f'Total loss: {tol}, Average IOU: {avg_iou}, Average Dice: {avg_dice}')\n",
    "            # 如果需要展示每个类别的指标\n",
    "            for i, (iou, dice) in enumerate(zip(iou_per_class, dice_per_class)):\n",
    "                logger.info(f'Class {i}: IOU={iou:.4f}, Dice={dice:.4f}')\n",
    "        if args.distributed != 'none':\n",
    "            sd = net.module.state_dict()\n",
    "        else:\n",
    "            sd = net.state_dict()\n",
    "\n",
    "        if edice > best_dice:\n",
    "            best_tol = tol\n",
    "            is_best = True\n",
    "\n",
    "            save_checkpoint({\n",
    "            'epoch': epoch + 1,\n",
    "            'model': args.net,\n",
    "            'state_dict': sd,\n",
    "            'best_tol': best_dice,\n",
    "            'path_helper': args.path_helper,\n",
    "        }, is_best, args.path_helper['ckpt_path'], filename=\"best_dice_checkpoint.pth\")\n",
    "        else:\n",
    "            is_best = False\n",
    "\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7f99538a81e8449c1b1a4a7141984025c678b5d9c33981aa2a3c129d8e1c90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
